{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graduate Rotational Internship Program - The Sparks Foundation, SG\n",
    "\n",
    "## GRIP - Computer Vision & IoT - Task 1 (Object Detection Using MobileNet & SSD)\n",
    "\n",
    "**Avish Jha**\\\n",
    "[LinkedIn](https://linkedin.com/in/avishj/) [GitHub](https://github.com/avishj/) [Website](https://avishj.dev/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object detection, a subset of computer vision, is an automated method for locating interesting objects in an image with respect to the background. Solving the object detection problem means placing a tight bounding box around these objects and associating the correct object category with each bounding box. Like other computer vision tasks, deep learning is the state-of-art method to perform object detection. MobileNet is an efficient and portable CNN architecture that is used in real world applications. MobileNets primarily use depthwise seperable convolutions in place of the standard convolutions used in earlier architectures to build lighter models. Single Shot Detector's are used to ensure one shot can detect multiple objects, for example YOLO.\n",
    "\n",
    "In the current task, we shall utilise MobileNetSSD with a DNN Module in OpenCV to build our object detection system.\\\n",
    "Reference: [Object detection with deep learning and OpenCV - PyImageSearch](https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Handling Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initialising Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a set of bounding box colors for each class that was used to train MobileNet\n",
    "\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "\"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "\"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "\"sofa\", \"train\", \"tvmonitor\"]\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Loading Pre-Trained Model & Images to be Detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromCaffe('MobileNetSSD_deployprototxt.txt','MobileNetSSD_deploy.caffemodel')\n",
    "img = cv2.imread('imgs/multi2.jpg')\n",
    "img= cv2.resize(img, (500, 500))\n",
    "cv2.imshow(\"Detected\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Detecting Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Dimensions & Creating 500x500 Blob, then passing it to the DNN\n",
    "\n",
    "(h, w) = img.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(img, 0.007843,(500, 500), 127.5)\n",
    "net.setInput(blob)\n",
    "detections = net.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Labelling Predictions, Boxing Objects & Displaying the Probability  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, detections.shape[2]):\n",
    "    \n",
    "    # Extracting Confidence\n",
    "    \n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    \n",
    "    # Filtering Confidence with minimum 30%\n",
    "    \n",
    "    if confidence > 0.3 :\n",
    "        \n",
    "        # Extracting Index of Class Label & Computing Dimensions of the Bounding Box\n",
    "        \n",
    "        idx = int(detections[0, 0, i, 1])\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        \n",
    "        # Displaying the Probability\n",
    "        \n",
    "        label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
    "        print(\"{}\".format(label))\n",
    "        cv2.rectangle(img, (startX, startY), (endX, endY), COLORS[idx], 2)\n",
    "        y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "        cv2.putText(img, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Displaying Output Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Output\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Function to Detect & Output from Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_object(imgloc):\n",
    "    img = cv2.imread(\"imgs/\" + imgloc)\n",
    "    img = cv2.resize(img, (500, 500))\n",
    "    cv2.imshow(\"The Input: \", img)\n",
    "    cv2.waitKey(0)\n",
    "    (h, w) = img.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.007843,(200, 200), 127.5)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    for i in np.arange(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.3:\n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
    "            print(\"{}\".format(label))\n",
    "            cv2.rectangle(img, (startX, startY), (endX, endY), COLORS[idx], 2)\n",
    "            y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "            cv2.putText(img, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n",
    "    cv2.imshow(\"The Output:\", img)\n",
    "    cv2.waitKey(0)   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Testing the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cars.jpg:')\n",
    "detect_object('cars.jpg')\n",
    "print('dhs.jsp:')\n",
    "detect_object('dhs.jpg')\n",
    "print('dp.jpg')\n",
    "detect_object('dp.jpg')\n",
    "print('horse.jpg:')\n",
    "detect_object('horse.jpg')\n",
    "print('multi1.jpg:')\n",
    "detect_object('multi1.jpg')\n",
    "print('multi2.jpg:')\n",
    "detect_object('multi2.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
